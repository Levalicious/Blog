# Some thoughts on p2p networking

One of the topics I want to discuss on this blog is consensus, both in algorithmic and conceptual form. However, consensus is a very complex topic at times, and right now I want to talk about one of the reasons it is so frustrating. While consensus itself can be as simple as two individuals running into each other in a hallway and trying to figure out which way to move so they don't collide again, that is only consensus on a small scale. On a large scale, it is a complex beast of emergent behaviors, which are only amplified by the unreliability that characterizes the internet. As such, people try to design peer to peer networks for consensus systems to operate over, giving them both a closed and unified environment to function in. 

This allows us to address some of the problems that make consensus on the internet so complex and problematic. With a p2p network, we can tune parameters to, as best as we can, mitigate message unreliability and delays while potentially improving routing performance and broadcast propagation rates. It also lets us address some attacks that are possible in p2p networks over the internet, and allows us to deal with other factors that affect the stability of p2p networks. 

However, p2p networks are also chaotic beasts like consensus. There is a huge amount of complexity, a huge amount of data to transmit, and a potential huge number of nodes to support. When there is that much complexity to deal with, there is a lot you can do, but only some of it is feasible.

You could try to connect to as many nodes as possible, providing the network with churn resistance and shrinking the diameter of the network graph, which makes any routing through but that leaves your device non-functional, overloaded with routing packets. Reducing this reduces the network stability and routing speed.

There is no true solution to this problem: In graph theory, there's a problem called the [degree diameter problem](https://en.wikipedia.org.wiki/Degree_diameter_problem). It relates to p2p networks in that it asks how can we have as many nodes connected to the network as possible, so that each node only connects to _d_ other nodes and the distance between any two nodes in the network (in terms of nodes between them) is less than a number _k_?

This number is called the [Moore Bound](https://en.wikipedia.org/wiki/Moore_graph) and it tells us what the maximum possible network size with that _d_ value is. We know the value for some small graphs because we can exhaustively search all possible graphs of a certain size and check if they have certain properties. However, the bigger the graph is, the harder it is to check all possibilities. As such, the problem is only solved for some small graphs. [This link](https://en.wikipedia.org/wiki/Table_of_the_largest_known_graphs_of_a_given_diameter_and_maximal_degree) shows the biggest graphs found with a certain value of _d_ and _k_. You'll notice that there are a few bolded numbers, indicating that those graphs are optimal, but that the vast majority are unsolved and only approximations are known.

Back to networking.

Even though there is no solution to this, there are mitigations. A p2p network like Bitcoin's is randomly connected: that is, a node joining the network connects to a random set of peers, even if it is a constant number, and if one of its peers leaves the network, it will randomly select another peer.

This structure is nice in that it is easy to implement, it it tends to be fairly robust. Bitcoin does have some modifications it implements on top of this: it allows a maximum of 125 peers, 10 of which can be outbound, and at most 115 of which can be inbound. Of the 10 outbound, 8 can be full connections and 2 can only transmit blocks. However beyond those limitations, it is completely random (with bias from the DNS seeds, although with a network as large as Bitcoin's that almost becomes a self-mitigating problem). 

Ethereum does something different, although it only really uses it for peer discovery. Like in BitTorrent, there is a [DHT](https://en.wikipedia.org/wiki/Distributed_hash_table)(distributed hash table) that the Ethereum network uses to store data. Where torrent uses it to store and transfer files published to the network, Ethereum uses it to share identifiers that specify the public key of a node as well as its IP and port, so other nodes can find this identifier and connect to it.

This has a few advantages, some of which Ethereum takes advantage of and others that it doesn't. 

A distributed hash table allows you to route a message to any node in the table, even if they aren't one of your immediate peers, or even a peer of a peer. In the case that your target isn't in the network, like how torrent stores files, your message will get delivered to the nodes on the network with the closest ID to your target, by [hamming distance](https://en.wikipedia.org/wiki/Hamming_distance).  This means if you want to send a message to someone in the network, you no longer have to broadcast it to everyone in the network, potentially overtaxing the network. Because of this, the Bitcoin network can never be used for anything other than Bitcoin: a significant change in chain architecture could require a full rewrite of their networking stack. Although we all know Bitcoin's never gonna have a significant change in architecture. They're the grandpa in the chair yelling, "Back in my day we didn't need sharding!". 

The type of DHT that Ethereum and BitTorrent use is called [Kademlia](https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf), although they both have their own modifications on the base idea. DHT routing in systems like Kademlia is near-optimal, reducing the distance between two nodes communicating to approximately $log_{2^b} n$ hops, where $2^b$ is the branching factor of the [radix tree](https://en.wikipedia.org/wiki/Radix_tree) that underlies this system. Kademlia is a topic worthy of its own article, one I'll hopefully write later and link to this, but until then we'll just stick to saying it's very good at near-optimal routing, and it doesn't flood the network in the process.

Another feature that Kademlia has, or at least it has as described in the paper and in BitTorrent, is the ability to "self-heal". That means, even under heavy churn (a lot of peers joining and leaving, which causes a lot of traffic when nodes have to adjust their peer tables accordingly and then disconnect and connect to other nodes based on that), the network will eventually, as best as it can, recover. The reason it can do this is because each node can ask its neighbors to know who they're connected to. If the network suddenly looses a bunch of nodes, the nodes will sort of bunch together to shrink the network until it can form a mostly-cohesive whole again.

In fact, it can use this property to heal pretty much any damage to the network: any partition, so long as either portion has a benevolent node that either has a connection to a benevolent node on the other portion, or remembers and will share the IP of another benevolent node on that other portion, will eventually heal. It may take a while, and it can be stopped if a malicious actor notices it and somehow attacks those nodes, or manages an [eclipse attack](https://cs-people.bu.edu/heilman/eclipse/) on the recovering portion of the network, but a couple benevolent connections is all it takes to start healing the network, and the better connected the network is, the more resilient it is to such damage in the first place.

Ethereum doesn't really take advantage of the routing feature much, which is a little sad, but it makes heavy use of the self-healing properties to ensure the network stays not only connected, but well-connected for every node in the network.

There is also [S/Kademlia](https://git.gnunet.org/bibliography.git/plain/docs/SKademlia2007.pdf), which makes Kademlia more resistant to attacks like eclipse attacks and malicious nodes in the message routing path, and, in systems other than blockchains which lack cryptographic signing and IDs, sybil attacks. This also provides some slight extra resistance to maliciously caused high churn. With some extra features, it could be adapted to make the network more Denial-of-Service resistant, both from network DoS attacks and from DoS attacks on the DHT storage of the node/network.

These systems don't completely solve the problem of minimizing the network diameter, but they do a lot. On the other hand, it also turns out that minimizing the network diameter isn't necessarily that important: While torrents need the DHT for file lookups and Ethereum needs to minimize its diameter because of how low they push their block times, other networks get by just fine without any sort of structure. Bitcoin's 10 minute block time has been keeping their network (mostly) healthy for over a decade now, showing that even a randomly connected network can handle churn easily.

It turns out that churn tends to affect structured networks more: however, this is the tradeoff one makes for predictable routing. The more predictions you make about where another node is, the more likely you are to be wrong, the further into the future you go. In certain systems, however, the tradeoff is more than worth it, and only very complex and theoretical systems design network structures that can be easily partitioned, often to experiment on pushing the bounds of routing performance.

There's another reason Bitcoin uses a random network that I haven't mentioned: anonymity. Finding a node's IP in a structured p2p network is much easier than in a random one, where you practically have to search the whole network. 

Even as we mitigate some of the problems that p2p problems fix for consensus systems, we encounter and even cause others.

There are systems for mitigating observers attempting to de-anonymize nodes. The [Dandelion](https://arxiv.org/abs/1701.04439) system and its successor, [Dandelion++](https://arxiv.org/abs/1805.11060) both attempt to do this. the implementation of Dandelion++ can be found [here](https://github.com/mimblewimble/grin/pull/2628). However, these both only help guarantee sender anonymity. 

One can attempt to guarantee full anonymity by adding the option to send transactions over Tor, which I believe some Bitcoin wallets can do, unless I'm remembering incorrectly. If anyone wants to post an issue, I'll update this accordingly.

Tor uses a technique called [onion routing](https://en.wikipedia.org/wiki/Onion_routing), in which a node wraps a message in multiple layers of encryption and the nodes in between the sender and the destination peel back the layers of encryption, along with routing information telling them where to send it, at each hop. A node only knows where it got a message from and where to send it, so a few hops help hide the sender from the receiver. However, this doesn't prevent someone watching the entire network, or if not that, entire 'chains' of communication between a sender and receiver from seeing connections, or from de-anonymizing users through other means. There are many papers about attacks on Tor. I recommend reading them, some of them are quite good.

I2P tries to mitigate this problem using a similar technique called [garlic routing](https://en.wikipedia.org/wiki/Garlic_routing). Instead of wrapping individual messages in layers of encryption, multiple messages, each with their own route, get wrapped together in layers. I've heard that this is also susceptible to a smaller but still significant subset of the attacks Tor is weak to, but I am not well read enough on the subject of I2P to comment on it. However. Given a global observer, I2P is also supposedly susceptible to de-anonymization.

One technique that is supposed to be secure even against a global observer is a [mixnet](https://en.wikipedia.org/wiki/Mix_network). However, the problem with mixnets is that while very good at anonymizing users, they are very slow. One of their mechanisms for anonymization is to collect received messages that it needs to relay, and only relay them (all at once) when a threshold is reached, either in time or in the number of messages it has. This makes message propagation potentially extremely slow.

I've thought quite a bit about what kind of blockchain I would like to design, and as such, I've also thought quite a bit about the p2p network I would want it to work over.

While there are theoretical models for truly secure p2p networks via quantum protocols and other such fancy things, and while I do believe we will see quantum 'supremacy' (what a terrible term) achieved within the next 5 years, I don't think that quantum computers will be useful to the general populace for a long time, much less commercially available, affordable, or even viable. As always, we'll see.

Anyway, back to my ideal p2p network.

I'd most likely base it off S/Kademlia. While there are other attractive DHTs, and other p2p architectures that do better jobs of resisting things like eclipse, DoS, and sybil attacks automatically, S/Kademlia is both 'simple enough', and gives decent guarantees about network routing, which I would plan to make plenty of use of. I would almost definitely plan to make use of Dandelion++ or something similar. I'm unsure how I feel about using a mixnet. While I feel that with the routing properties of Kademlia I could make it decently fast for a blockchain, I'm not sure if I would be satisfied with that. Also, there are interesting constructions which involve [incentivizing message routing](https://ethresear.ch/t/incentivizing-a-robust-p2p-network-relay-layer/1438) that I find interesting and kind of like: Imagine if everyone's devices were linked in a p2p network over radio waves and shared each other's connections; freeloaders automatically being prevented by an ephemeral (or maybe even real) cost to them using the network without helping it in turn.

It's not gonna happen anytime soon, if ever, but it's a cute little fantasy, and the idea has uses for normal p2p networks, even if they aren't some magic globe-spanning network (This is definitely a topic I will revisit in the future).

I'd allow for messages directly to node IDs and broadcasts to topics in the network, via some [gossipsub](https://github.com/libp2p/specs/tree/master/pubsub/gossipsub)-inspired mechanism.

We'll see. There's a lot of cool ideas that would take a long time to put together. I've tinkered with pieces of a system approaching this for years, but I'm nowhere near a functional system.

Anyway, I've tossed a lot of information at you. I'll be lucky if it's even half-coherent.

Thanks for reading.

Lev